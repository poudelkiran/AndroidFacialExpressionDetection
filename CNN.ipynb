{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9d378e7df9d164dc184c663e2abfda0eea4f4372"
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\ndataset_path = '../input/fer2013.csv'\nimage_size=(48,48)\n \n# Load Dataset\ndef load_fer2013():\n    data = pd.read_csv(dataset_path)\n    pixels = data['pixels'].tolist()\n    width, height = 48, 48\n    faces = []\n    for pixel_sequence in pixels:\n        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n        face = np.asarray(face).reshape(width, height)\n        face = cv2.resize(face.astype('uint8'),image_size)\n        faces.append(face.astype('float32'))\n    faces = np.asarray(faces)\n    faces = np.expand_dims(faces, -1)\n    emotions = pd.get_dummies(data['emotion']).as_matrix()\n    return faces, emotions\n#  Preprocess the dataset\ndef preprocess_input(x):\n    x = x.astype('float32')\n    x = x / 255.0\n    return x\n \nfaces, emotions = load_fer2013()\nfaces = preprocess_input(faces)\nxtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Build a Model and Train\nfrom keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Activation, Convolution2D, Dropout, Conv2D\nfrom keras.layers import AveragePooling2D, BatchNormalization\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.models import Sequential\nfrom keras.layers import Flatten\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import SeparableConv2D\nfrom keras import layers\nfrom keras.regularizers import l2\nimport pandas as pd\nimport cv2\nimport numpy as np\n \n# parameters\nbatch_size = 32\nnum_epochs = 500\ninput_shape = (48, 48, 1)\nverbose = 1\nnum_classes = 7\npatience = 50\nl2_regularization=0.01\n \n# data generator\ndata_generator = ImageDataGenerator(\n                        featurewise_center=False,\n                        featurewise_std_normalization=False,\n                        rotation_range=10,\n                        width_shift_range=0.1,\n                        height_shift_range=0.1,\n                        zoom_range=.1,\n                        horizontal_flip=True)\n \n# model parameters\nregularization = l2(l2_regularization)\n \n# base\nimg_input = Input(input_shape)\nx = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(img_input)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\n \n# module 1\nresidual = Conv2D(16, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\nresidual = BatchNormalization()(residual)\nx = SeparableConv2D(16, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = SeparableConv2D(16, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\nx = layers.add([x, residual])\n \n# module 2\nresidual = Conv2D(32, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\nresidual = BatchNormalization()(residual)\nx = SeparableConv2D(32, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = SeparableConv2D(32, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\nx = layers.add([x, residual])\n \n# module 3\nresidual = Conv2D(64, (1, 1), strides=(2, 2),padding='same', use_bias=False)(x)\nresidual = BatchNormalization()(residual)\nx = SeparableConv2D(64, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = SeparableConv2D(64, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\nx = layers.add([x, residual])\n \n# module 4\nresidual = Conv2D(128, (1, 1), strides=(2, 2),padding='same', use_bias=False)(x)\nresidual = BatchNormalization()(residual)\nx = SeparableConv2D(128, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = SeparableConv2D(128, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\nx = layers.add([x, residual])\nx = Conv2D(num_classes, (3, 3), padding='same')(x)\nx = GlobalAveragePooling2D()(x)\noutput = Activation('softmax',name='predictions')(x)\n \nmodel = Model(img_input, output)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.summary()\n \n# callbacks\nlog_file_path = '_emotion_training.log'\ncsv_logger = CSVLogger(log_file_path, append=False)\nearly_stop = EarlyStopping('val_loss', patience=patience)\nreduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=int(patience/4), verbose=1)\n\nmodel_names = 'hdf5file.hdf5'\nmodel_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,save_best_only=True)\ncallbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n \nmodel.fit_generator(data_generator.flow(xtrain, ytrain,batch_size),\n                        steps_per_epoch=len(xtrain) / batch_size,\n                        epochs=num_epochs, verbose=1, callbacks=callbacks,\n                        validation_data=(xtest,ytest))\n",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}